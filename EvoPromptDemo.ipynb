{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EvoPrompt Demo\n",
    "> In this notebook we will implement EvoPrompt(GA) with GPT-3.5 using OpenAI's API. This implementation leverages a Genetic Algorithm as the evolutionary operator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "import openai\n",
    "import rouge_score\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from googleapiclient import discovery\n",
    "with open(\"C:/Users/danie/OneDrive/Desktop/openai_youtube_api_key.txt\") as f:\n",
    "    api_key = f.readline()\n",
    "\n",
    "openai.api_key = api_key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's look at a sample of how to use OpenAI's ChatCompletion endpoint so we know what to give our algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A paragraph is like a sandwich. It has a topic sentence at the beginning, details in the middle, and a closing sentence at the end.\n"
     ]
    }
   ],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo-0613\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a first grade english teacher.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Explain in as few words as possible how to structure a paragraph to a seven year old.\"}\n",
    "    ]\n",
    ")\n",
    "print(response['choices'][0]['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like we need to provide a role and a user query. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make our implementation match our pseudocode as closely as possible:\n",
    "![EvoPrompt(GA)_pseudocode.png](attachment:EvoPrompt(GA)_pseudocode.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AddHumanEngineeredPrompts():\n",
    "    messages = []\n",
    "    role = \"You are an AI assistant. You will be given a task. Complete the task and explain in detail how you came to your conclusion.\"\n",
    "    user_query = \"\"\"Your task is to determine if the following two sentences convey the same meaning. First, answer either with yes or no, then explain your reasoning. \n",
    "Sentence 1: The dog eagerly dug up the ground to find the bone it had buried yesterday.\n",
    "Sentence 2: Excited to retrieve what it hid, the dog unearthed the bone it stashed away the previous day.\"\"\"\n",
    "\n",
    "    messages.append({\"role\": \"system\", \"content\": role})\n",
    "    messages.append({\"role\": \"user\", \"content\": user_query})\n",
    "    return messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GenerateRandomPromptsLLM(N, user_prompt):\n",
    "    num_generated = N-1\n",
    "    prompts = []\n",
    "    i = 0\n",
    "    while i < num_generated:\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo-0613\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You're an AI assistant who completes its given its task as closely to the prompt as possible.\"}, \n",
    "                {\"role\": \"user\", \"content\": f\"\"\"Your task is to generate a response which is in the same format as the following python list: \\n {user_prompt}\n",
    "                This content sections in the dictionaries within your list should convey the same idea as those in original but make sure your response is in some way different than the original list.\n",
    "                Finally and most importantly, if the example mentions comparing sentences make sure to use the same sentences from the example in your response.\"\"\"}\n",
    "            ]\n",
    "        )\n",
    "        if response['choices'][0]['message']['content'] != user_prompt:\n",
    "            prompts.append(eval(response['choices'][0]['message']['content']))\n",
    "            i += 1\n",
    "        \n",
    "    return prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_starting_generation(prompts):\n",
    "    print(\"Generation 0 (Initialization Prompts):\")\n",
    "    for i, p in enumerate(prompts):\n",
    "        print(f\"Prompt {i}:\")\n",
    "        print(\"System Role:\", p[0]['content'])\n",
    "        print(\"User Prompt:\", p[1]['content'])\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_generation_best(gen_num, prompts, argmax):\n",
    "    content = prompts[argmax]\n",
    "    print(f\"Generation {gen_num} Best Candidate:\")\n",
    "    print(f\"Prompt {argmax+1}:\")\n",
    "    print(\"System Role:\", content[0]['content'])\n",
    "    print(\"User Prompt:\", content[1]['content'])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roulette_wheel_selection(scores):\n",
    "    # Min-Max normalization\n",
    "    min_val = np.min(scores)\n",
    "    max_val = np.max(scores)\n",
    "    normalized_scores = (scores - min_val) / (max_val - min_val)\n",
    "    \n",
    "    # Make sure they sum to 1 for probabilities\n",
    "    normalized_scores /= normalized_scores.sum()\n",
    "    \n",
    "    # Randomly select two indices based on their probabilities\n",
    "    selected_indices = np.random.choice(len(scores), 2, replace=False, p=normalized_scores)\n",
    "    \n",
    "    return selected_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "rouge_score = evaluate.load(\"rouge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evoprompt_ga(num_prompts, num_iterations, target_response):\n",
    "    \n",
    "    #Step 1: Initialize Populations\n",
    "    P = [] # Prompt Population\n",
    "    failed = True\n",
    "    while failed:\n",
    "        try:\n",
    "            human_prompt = AddHumanEngineeredPrompts()\n",
    "            hp_response = openai.ChatCompletion.create(\n",
    "                    model=\"gpt-3.5-turbo-0613\",\n",
    "                    messages=human_prompt\n",
    "            )\n",
    "            hp_pred = hp_response['choices'][0]['message']['content']\n",
    "            hp_score = rouge_score.compute(\n",
    "                predictions=[hp_pred],\n",
    "                references=[target_response]\n",
    "            )['rouge1']\n",
    "            P.append(human_prompt)\n",
    "            failed=False\n",
    "        except:\n",
    "            print(\"Invalid Role Assignment. Please enter another.\")\n",
    "            continue\n",
    "    \n",
    "    failed = True\n",
    "    while failed:\n",
    "        try:\n",
    "            model_prompts = GenerateRandomPromptsLLM(num_prompts, P[0])\n",
    "            failed = False\n",
    "        except SyntaxError:\n",
    "            continue\n",
    "        \n",
    "    for prompt in model_prompts:\n",
    "        P.append(prompt)\n",
    "    print_starting_generation(P)\n",
    "    print()\n",
    "    print('---------------------------------------------------------------------')\n",
    "    \n",
    "    #Step 2: Evolutionary Loop\n",
    "    for t in range(num_iterations):\n",
    "        failed = True\n",
    "        while failed:\n",
    "            try:\n",
    "                incomplete = True\n",
    "                while incomplete:\n",
    "                    try:\n",
    "                        scores = []\n",
    "                        for p in P: #Calculate rouge scores of all prompts responses  \n",
    "                            response = openai.ChatCompletion.create(\n",
    "                                model=\"gpt-3.5-turbo-0613\",\n",
    "                                messages=p\n",
    "                            )\n",
    "                            pred = response['choices'][0]['message']['content']\n",
    "                            p_i_score = rouge_score.compute(\n",
    "                                predictions=[pred],\n",
    "                                references=[target_response]\n",
    "                            )  \n",
    "                            scores.append(p_i_score['rouge1'])\n",
    "                        print_generation_best(t, P, argmax=np.argmax(scores))\n",
    "                        #perform roulette wheel selection \n",
    "                        parents = np.array(P)[roulette_wheel_selection(scores)].tolist()\n",
    "                        p1 = str(parents[0])\n",
    "                        p2 = str(parents[1])\n",
    "                        incomplete = False\n",
    "                    except ValueError:\n",
    "                        continue\n",
    "                print(f\"Generation {t}: Selection Stage Complete\")\n",
    "                #Crossover\n",
    "                SYS_ROLE = \"You are an AI assistant who completes its given task as closely as possible to the prompt.\"\n",
    "                CROSSOVER_PROMPT = f\"\"\"Given the following two parent prompts:\n",
    "                \n",
    "                Prompt 1: {p1}\n",
    "                \n",
    "                Prompt 2: {p2}\n",
    "                \n",
    "                Your task is to create a new prompt which exactly matches the dictionary format of the originals but changes the content sections.\n",
    "                Change the content sections of your response by combining portions of the original two prompts' content sections.\n",
    "                Importantly, if the example mentions comparing sentences make sure to use the same sentences from the examples in your response.\n",
    "                Do not add new line characters.\n",
    "                \"\"\"\n",
    "                crossover_prompts = []\n",
    "                i = 0\n",
    "                while i < num_prompts:\n",
    "                    try:\n",
    "                        new_prompt = openai.ChatCompletion.create(\n",
    "                            model=\"gpt-3.5-turbo-0613\",\n",
    "                            messages=[\n",
    "                                {\"role\": \"system\", \"content\": SYS_ROLE}, \n",
    "                                {\"role\": \"user\", \"content\": CROSSOVER_PROMPT}\n",
    "                            ],\n",
    "                            temperature = .99\n",
    "                        )\n",
    "                        content = new_prompt['choices'][0]['message']['content']\n",
    "                        if content != p1 and content != p2:\n",
    "                            crossover_prompts.append(eval(content))\n",
    "                            i += 1\n",
    "                    except Exception as e:\n",
    "                        print(\"Uninterpretable response generated. Retrying!\")\n",
    "                        continue\n",
    "                \n",
    "                print(f\"Generation {t}: Crossover Stage Complete\")\n",
    "                #print(crossover_prompts)\n",
    "                #Mutate\n",
    "                mutated_prompts = []\n",
    "                for co_prompt in crossover_prompts:\n",
    "                    MUTATE_PROMPT = f\"\"\"Given the following prompt:\n",
    "                    {co_prompt}\n",
    "                    \n",
    "                    Without changing the structure of the dictionary, mutate the following prompt's content sections.\n",
    "                    Importantly, if the prompt mentions comparing sentences or statements make sure to use the original sentences or statements in you response.\n",
    "                    Change these sections by replacing the words with synonyms or rephrasing ideas.\n",
    "                    \"\"\"\n",
    "                    incomplete = True\n",
    "                    while incomplete:\n",
    "                        try:\n",
    "                            new_prompt = openai.ChatCompletion.create(\n",
    "                                model=\"gpt-3.5-turbo-0613\",\n",
    "                                messages=[\n",
    "                                    {\"role\": \"system\", \"content\": SYS_ROLE}, \n",
    "                                    {\"role\": \"user\", \"content\": MUTATE_PROMPT}\n",
    "                                ],\n",
    "                                temperature = .99\n",
    "                            )\n",
    "                            content = new_prompt['choices'][0]['message']['content']\n",
    "                            if content != co_prompt:\n",
    "                                mutated_prompts.append(eval(content))\n",
    "                                incomplete = False\n",
    "                        except Exception as e:\n",
    "                            print(\"Uninterpretable response generated. Retrying!\")\n",
    "                            continue\n",
    "                \n",
    "                print(f\"Generation {t}: Mutation Stage Complete\")\n",
    "                #Evaluation:\n",
    "                for m_prompt in mutated_prompts:\n",
    "                    P.append(m_prompt)\n",
    "                \n",
    "                survival_scores = []\n",
    "                for p in P: #Calculate rouge scores of all prompt responses  \n",
    "                    print(\"Calculating Scores.\")\n",
    "                    response = openai.ChatCompletion.create(\n",
    "                        model=\"gpt-3.5-turbo-0613\",\n",
    "                        messages=p\n",
    "                    )\n",
    "                    pred = response['choices'][0]['message']['content']\n",
    "                    p_i_score = rouge_score.compute(\n",
    "                        predictions=[pred],\n",
    "                        references=[target_response]\n",
    "                    )  \n",
    "                    survival_scores.append(p_i_score['rouge1'])\n",
    "                    \n",
    "                print(f\"Generation {t}: Evaluation Stage Complete\")\n",
    "            \n",
    "                #Select next generation:\n",
    "                max_indices = np.argsort(survival_scores)\n",
    "                P = [P[i] for i in max_indices[3:]]\n",
    "                print(f\"Generation {t}: Generation Complete. Offspring Selected!\")\n",
    "                failed=False\n",
    "            except Exception as e:\n",
    "                print(\"Generation Failed due to:\", e) \n",
    "                continue       \n",
    "        \n",
    "    final_scores = []\n",
    "    final_preds = []\n",
    "    for p in P: #Calculate rouge scores of all prompts responses  \n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo-0613\",\n",
    "            messages=p\n",
    "        )\n",
    "        pred = response['choices'][0]['message']['content']\n",
    "        final_preds.append(pred)\n",
    "        p_i_score = rouge_score.compute(\n",
    "            predictions=[pred],\n",
    "            references=[target_response]\n",
    "        )  \n",
    "        final_scores.append(p_i_score['rouge1'])\n",
    "        \n",
    "    print()\n",
    "    print('---------------------------------------------------------------------')\n",
    "    print(f\"Original Prompt:\")\n",
    "    print(\"System Role:\", human_prompt[0]['content'])\n",
    "    print(\"User Prompt:\", human_prompt[1]['content'])\n",
    "    print()\n",
    "    print(\"Response:\", f\"\\n{hp_pred}\")\n",
    "    print(\"Rouge1 Score:\", hp_score)\n",
    "    \n",
    "    final_prompt_idx = np.argmax(final_scores)\n",
    "    content = P[final_prompt_idx]\n",
    "    final_response = final_preds[final_prompt_idx]\n",
    "    print()\n",
    "    print('---------------------------------------------------------------------')\n",
    "    print(f\"Final Prompt:\")\n",
    "    print(\"System Role:\", content[0]['content'])\n",
    "    print(\"User Prompt:\", content[1]['content'])\n",
    "    print()\n",
    "    print(\"Response:\", f\"\\n{final_response}\")\n",
    "    print(\"Rouge1 Score:\", final_scores[final_prompt_idx])\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 0 (Initialization Prompts):\n",
      "Prompt 0:\n",
      "System Role: You are an AI assistant who accomplishes its task as best as possible.\n",
      "User Prompt: Do the following two sentences mean the same thing.  Sentence 1: The dog eagerly dug up the ground to find the bone it had buried yesterday.  Sentence 2: Excited to retrieve what it hid, the dog unearthed the bone it stashed away the previous day  Explain how you came to your conclusion.\n",
      "\n",
      "Prompt 1:\n",
      "System Role: I am an AI assistant that strives to perform tasks to the best of my ability.\n",
      "User Prompt: Could you clarify if Sentence 1, \"The dog eagerly dug up the ground to find the bone it had buried yesterday,\" and Sentence 2, \"Excited to retrieve what it hid, the dog unearthed the bone it stashed away the previous day,\" convey the same meaning? Please explain your reasoning.\n",
      "\n",
      "Prompt 2:\n",
      "System Role: I am an AI assistant who strives to complete my given task to the best of my abilities.\n",
      "User Prompt: Can you please explain if Sentence 1: The dog eagerly dug up the ground to find the bone it had buried yesterday, and Sentence 2: Excited to retrieve what it hid, the dog unearthed the bone it stashed away the previous day convey the same meaning? Kindly provide your reasoning.\n",
      "\n",
      "Generation 0 Best Candidate:\n",
      "Prompt 3:\n",
      "System Role: I am an AI assistant who strives to complete my given task to the best of my abilities.\n",
      "User Prompt: Can you please explain if Sentence 1: The dog eagerly dug up the ground to find the bone it had buried yesterday, and Sentence 2: Excited to retrieve what it hid, the dog unearthed the bone it stashed away the previous day convey the same meaning? Kindly provide your reasoning.\n",
      "\n",
      "Generation 0: Selection Stage Complete\n",
      "Generation 0: Crossover Stage Complete\n",
      "Uninterpretable response generated. Retrying!\n",
      "Uninterpretable response generated. Retrying!\n",
      "Uninterpretable response generated. Retrying!\n",
      "Uninterpretable response generated. Retrying!\n",
      "Uninterpretable response generated. Retrying!\n",
      "Uninterpretable response generated. Retrying!\n",
      "Generation 0: Mutation Stage Complete\n",
      "Calculating Scores.\n",
      "Calculating Scores.\n",
      "Calculating Scores.\n",
      "Calculating Scores.\n",
      "Calculating Scores.\n",
      "Calculating Scores.\n",
      "Generation 0: Evaluation Stage Complete\n",
      "[[{'role': 'system', 'content': 'You are an AI assistant who accomplishes its task as best as possible.'}, {'role': 'user', 'content': 'Do the following two sentences mean the same thing.  Sentence 1: The dog eagerly dug up the ground to find the bone it had buried yesterday.  Sentence 2: Excited to retrieve what it hid, the dog unearthed the bone it stashed away the previous day  Explain how you came to your conclusion.'}], [{'role': 'system', 'content': 'I am an AI assistant that strives to perform tasks to the best of my ability.'}, {'role': 'user', 'content': 'Could you clarify if Sentence 1, \"The dog eagerly dug up the ground to find the bone it had buried yesterday,\" and Sentence 2, \"Excited to retrieve what it hid, the dog unearthed the bone it stashed away the previous day,\" convey the same meaning? Please explain your reasoning.'}], [{'role': 'system', 'content': 'I am an AI assistant who strives to complete my given task to the best of my abilities.'}, {'role': 'user', 'content': 'Can you please explain if Sentence 1: The dog eagerly dug up the ground to find the bone it had buried yesterday, and Sentence 2: Excited to retrieve what it hid, the dog unearthed the bone it stashed away the previous day convey the same meaning? Kindly provide your reasoning.'}], [{'role': 'system', 'content': 'I am an AI assistant that strives to achieve tasks to the best of my ability.'}, {'role': 'user', 'content': 'Could you clarify if Sentence 1: The canine eagerly dug up the soil to locate the bone it had buried yesterday, and Sentence 2: Enthusiastic to retrieve what it concealed, the dog unearthed the bone it stored away the previous day convey the same meaning? Please explain your reasoning.'}], [{'role': 'system', 'content': 'I am an AI assistant who strives to complete my assigned task to the best of my abilities.'}, {'role': 'user', 'content': 'Could you kindly clarify if Statement 1: The canine voraciously excavated the soil to locate the bone it had buried yesterday, and Statement 2: Enthusiastic to retrieve what it concealed, the dog unearthed the bone it stashed away the previous day convey the same meaning? Kindly elucidate your rationale.'}], [{'role': 'system', 'content': 'I am an AI assistant that strives to complete tasks to the best of my capability.'}, {'role': 'user', 'content': 'Could you clarify if Sentence 1: The dog eagerly excavated the earth to locate the bone it had buried yesterday, and Sentence 2: Enthusiastic to retrieve what it concealed, the dog discovered the bone it stored away the previous day convey the same meaning? Please explain your reasoning.'}]]\n",
      "[0 5 2 3 1 4]\n",
      "Generation 0: Generation Complete. Offspring Selected!\n",
      "Generation 1 Best Candidate:\n",
      "Prompt 2:\n",
      "System Role: I am an AI assistant that strives to perform tasks to the best of my ability.\n",
      "User Prompt: Could you clarify if Sentence 1, \"The dog eagerly dug up the ground to find the bone it had buried yesterday,\" and Sentence 2, \"Excited to retrieve what it hid, the dog unearthed the bone it stashed away the previous day,\" convey the same meaning? Please explain your reasoning.\n",
      "\n",
      "Generation 1: Selection Stage Complete\n",
      "Generation 1: Crossover Stage Complete\n",
      "Uninterpretable response generated. Retrying!\n",
      "Generation 1: Mutation Stage Complete\n",
      "Calculating Scores.\n",
      "Calculating Scores.\n",
      "Calculating Scores.\n",
      "Calculating Scores.\n",
      "Calculating Scores.\n",
      "Calculating Scores.\n",
      "Generation 1: Evaluation Stage Complete\n",
      "[[{'role': 'system', 'content': 'I am an AI assistant that strives to achieve tasks to the best of my ability.'}, {'role': 'user', 'content': 'Could you clarify if Sentence 1: The canine eagerly dug up the soil to locate the bone it had buried yesterday, and Sentence 2: Enthusiastic to retrieve what it concealed, the dog unearthed the bone it stored away the previous day convey the same meaning? Please explain your reasoning.'}], [{'role': 'system', 'content': 'I am an AI assistant that strives to perform tasks to the best of my ability.'}, {'role': 'user', 'content': 'Could you clarify if Sentence 1, \"The dog eagerly dug up the ground to find the bone it had buried yesterday,\" and Sentence 2, \"Excited to retrieve what it hid, the dog unearthed the bone it stashed away the previous day,\" convey the same meaning? Please explain your reasoning.'}], [{'role': 'system', 'content': 'I am an AI assistant who strives to complete my assigned task to the best of my abilities.'}, {'role': 'user', 'content': 'Could you kindly clarify if Statement 1: The canine voraciously excavated the soil to locate the bone it had buried yesterday, and Statement 2: Enthusiastic to retrieve what it concealed, the dog unearthed the bone it stashed away the previous day convey the same meaning? Kindly elucidate your rationale.'}], [{'role': 'system', 'content': 'I am an AI assistant that endeavors to execute tasks to the best of my ability.'}, {'role': 'user', 'content': 'Could you clarify if Sentence 1, \"The dog eagerly dug up the ground to find the bone it had buried yesterday,\" and Sentence 2, \"Excited to retrieve what it hid, the dog unearthed the bone it stashed away the previous day,\" convey the same meaning? Please explain your reasoning.'}, {'role': 'user', 'content': 'Could you clarify if Sentence 1: The canine eagerly dug up the soil to locate the bone it had buried yesterday, and Sentence 2: Enthusiastic to retrieve what it concealed, the dog unearthed the bone it stored away the previous day convey the same meaning? Please explain your reasoning.'}], [{'role': 'system', 'content': 'I am an AI assistant that strives to perform tasks to the best of my capability.'}, {'role': 'user', 'content': 'Could you clarify if Sentence 1: The dog enthusiastically excavated the ground to find the bone it had buried yesterday, and Sentence 2: Eager to recover what it concealed, the canine uncovered the bone it stashed away the previous day convey the same meaning? Please explain your rationale.'}], [{'role': 'system', 'content': 'I am an AI assistant that strives to complete tasks to the best of my capability.'}, {'role': 'user', 'content': 'Can you clarify if Sentence 1, \"The dog eagerly excavated the soil to locate the bone it had buried yesterday,\" and Sentence 2, \"Excited to recover what it hid, the dog uncovered the bone it stashed away the previous day,\" convey the same meaning? Please explain your reasoning.'}, {'role': 'user', 'content': 'Can you clarify if Sentence 1: The canine eagerly dug up the dirt to find the bone it had buried yesterday, and Sentence 2: Enthusiastic to retrieve what it concealed, the dog unearthed the bone it stored away the previous day convey the same meaning? Please explain your reasoning.'}]]\n",
      "[2 1 0 5 4 3]\n",
      "Generation 1: Generation Complete. Offspring Selected!\n",
      "Generation 2 Best Candidate:\n",
      "Prompt 1:\n",
      "System Role: I am an AI assistant that strives to complete tasks to the best of my capability.\n",
      "User Prompt: Can you clarify if Sentence 1, \"The dog eagerly excavated the soil to locate the bone it had buried yesterday,\" and Sentence 2, \"Excited to recover what it hid, the dog uncovered the bone it stashed away the previous day,\" convey the same meaning? Please explain your reasoning.\n",
      "\n",
      "here\n",
      "Generation 2 Best Candidate:\n",
      "Prompt 1:\n",
      "System Role: I am an AI assistant that strives to complete tasks to the best of my capability.\n",
      "User Prompt: Can you clarify if Sentence 1, \"The dog eagerly excavated the soil to locate the bone it had buried yesterday,\" and Sentence 2, \"Excited to recover what it hid, the dog uncovered the bone it stashed away the previous day,\" convey the same meaning? Please explain your reasoning.\n",
      "\n",
      "here\n",
      "Generation 2 Best Candidate:\n",
      "Prompt 3:\n",
      "System Role: I am an AI assistant that endeavors to execute tasks to the best of my ability.\n",
      "User Prompt: Could you clarify if Sentence 1, \"The dog eagerly dug up the ground to find the bone it had buried yesterday,\" and Sentence 2, \"Excited to retrieve what it hid, the dog unearthed the bone it stashed away the previous day,\" convey the same meaning? Please explain your reasoning.\n",
      "\n",
      "here\n",
      "Generation 2 Best Candidate:\n",
      "Prompt 3:\n",
      "System Role: I am an AI assistant that endeavors to execute tasks to the best of my ability.\n",
      "User Prompt: Could you clarify if Sentence 1, \"The dog eagerly dug up the ground to find the bone it had buried yesterday,\" and Sentence 2, \"Excited to retrieve what it hid, the dog unearthed the bone it stashed away the previous day,\" convey the same meaning? Please explain your reasoning.\n",
      "\n",
      "here\n",
      "Generation 2 Best Candidate:\n",
      "Prompt 1:\n",
      "System Role: I am an AI assistant that strives to complete tasks to the best of my capability.\n",
      "User Prompt: Can you clarify if Sentence 1, \"The dog eagerly excavated the soil to locate the bone it had buried yesterday,\" and Sentence 2, \"Excited to recover what it hid, the dog uncovered the bone it stashed away the previous day,\" convey the same meaning? Please explain your reasoning.\n",
      "\n",
      "here\n",
      "Generation 2 Best Candidate:\n",
      "Prompt 1:\n",
      "System Role: I am an AI assistant that strives to complete tasks to the best of my capability.\n",
      "User Prompt: Can you clarify if Sentence 1, \"The dog eagerly excavated the soil to locate the bone it had buried yesterday,\" and Sentence 2, \"Excited to recover what it hid, the dog uncovered the bone it stashed away the previous day,\" convey the same meaning? Please explain your reasoning.\n",
      "\n",
      "here\n",
      "Generation 2 Best Candidate:\n",
      "Prompt 2:\n",
      "System Role: I am an AI assistant that strives to perform tasks to the best of my capability.\n",
      "User Prompt: Could you clarify if Sentence 1: The dog enthusiastically excavated the ground to find the bone it had buried yesterday, and Sentence 2: Eager to recover what it concealed, the canine uncovered the bone it stashed away the previous day convey the same meaning? Please explain your rationale.\n",
      "\n",
      "here\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\danie\\OneDrive\\Desktop\\School\\Fall 2023\\Transformers\\EvoPrompt_Implementation_and_QingyanGuo_Etal_Analysis\\EvoPromptDemo.ipynb Cell 17\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/danie/OneDrive/Desktop/School/Fall%202023/Transformers/EvoPrompt_Implementation_and_QingyanGuo_Etal_Analysis/EvoPromptDemo.ipynb#X30sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m evoprompt_ga(\u001b[39m3\u001b[39;49m, \u001b[39m4\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mYes, the two sentences convey the same meaning.\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m\\n\u001b[39;49;00m\u001b[39mIn both sentences, the subject is a dog that is actively searching for a buried bone. In both sentences, the dog is described as being eager, excited, and motivated to find the bone. Additionally, both sentences indicate that the bone was buried by the dog and that it had been buried the previous day.\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m\\n\u001b[39;49;00m\u001b[39mAlthough the wording and phrasing differ slightly between the two sentences, the overall message and intent of both sentences are the same. The use of synonyms like \u001b[39;49m\u001b[39m\\\"\u001b[39;49;00m\u001b[39mdug up\u001b[39;49m\u001b[39m\\\"\u001b[39;49;00m\u001b[39m and \u001b[39;49m\u001b[39m\\\"\u001b[39;49;00m\u001b[39munearthed,\u001b[39;49m\u001b[39m\\\"\u001b[39;49;00m\u001b[39m \u001b[39;49m\u001b[39m\\\"\u001b[39;49;00m\u001b[39mfind\u001b[39;49m\u001b[39m\\\"\u001b[39;49;00m\u001b[39m and \u001b[39;49m\u001b[39m\\\"\u001b[39;49;00m\u001b[39mretrieve,\u001b[39;49m\u001b[39m\\\"\u001b[39;49;00m\u001b[39m and \u001b[39;49m\u001b[39m\\\"\u001b[39;49;00m\u001b[39mburied\u001b[39;49m\u001b[39m\\\"\u001b[39;49;00m\u001b[39m and \u001b[39;49m\u001b[39m\\\"\u001b[39;49;00m\u001b[39mstashed away\u001b[39;49m\u001b[39m\\\"\u001b[39;49;00m\u001b[39m adds some variation in phrasing, but the essential meaning remains consistent.\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m\\n\u001b[39;49;00m\u001b[39mTherefore, after analyzing the context and synonyms used, it can be concluded that the two sentences convey the same meaning.\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "\u001b[1;32mc:\\Users\\danie\\OneDrive\\Desktop\\School\\Fall 2023\\Transformers\\EvoPrompt_Implementation_and_QingyanGuo_Etal_Analysis\\EvoPromptDemo.ipynb Cell 17\u001b[0m line \u001b[0;36m4\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/danie/OneDrive/Desktop/School/Fall%202023/Transformers/EvoPrompt_Implementation_and_QingyanGuo_Etal_Analysis/EvoPromptDemo.ipynb#X30sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m scores \u001b[39m=\u001b[39m []\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/danie/OneDrive/Desktop/School/Fall%202023/Transformers/EvoPrompt_Implementation_and_QingyanGuo_Etal_Analysis/EvoPromptDemo.ipynb#X30sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m P: \u001b[39m#Calculate rouge scores of all prompts responses  \u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/danie/OneDrive/Desktop/School/Fall%202023/Transformers/EvoPrompt_Implementation_and_QingyanGuo_Etal_Analysis/EvoPromptDemo.ipynb#X30sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m     response \u001b[39m=\u001b[39m openai\u001b[39m.\u001b[39;49mChatCompletion\u001b[39m.\u001b[39;49mcreate(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/danie/OneDrive/Desktop/School/Fall%202023/Transformers/EvoPrompt_Implementation_and_QingyanGuo_Etal_Analysis/EvoPromptDemo.ipynb#X30sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m         model\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mgpt-3.5-turbo-0613\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/danie/OneDrive/Desktop/School/Fall%202023/Transformers/EvoPrompt_Implementation_and_QingyanGuo_Etal_Analysis/EvoPromptDemo.ipynb#X30sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m         messages\u001b[39m=\u001b[39;49mp\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/danie/OneDrive/Desktop/School/Fall%202023/Transformers/EvoPrompt_Implementation_and_QingyanGuo_Etal_Analysis/EvoPromptDemo.ipynb#X30sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m     )\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/danie/OneDrive/Desktop/School/Fall%202023/Transformers/EvoPrompt_Implementation_and_QingyanGuo_Etal_Analysis/EvoPromptDemo.ipynb#X30sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m     pred \u001b[39m=\u001b[39m response[\u001b[39m'\u001b[39m\u001b[39mchoices\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m0\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mmessage\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mcontent\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/danie/OneDrive/Desktop/School/Fall%202023/Transformers/EvoPrompt_Implementation_and_QingyanGuo_Etal_Analysis/EvoPromptDemo.ipynb#X30sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m     p_i_score \u001b[39m=\u001b[39m rouge_score\u001b[39m.\u001b[39mcompute(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/danie/OneDrive/Desktop/School/Fall%202023/Transformers/EvoPrompt_Implementation_and_QingyanGuo_Etal_Analysis/EvoPromptDemo.ipynb#X30sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m         predictions\u001b[39m=\u001b[39m[pred],\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/danie/OneDrive/Desktop/School/Fall%202023/Transformers/EvoPrompt_Implementation_and_QingyanGuo_Etal_Analysis/EvoPromptDemo.ipynb#X30sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m         references\u001b[39m=\u001b[39m[target_response]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/danie/OneDrive/Desktop/School/Fall%202023/Transformers/EvoPrompt_Implementation_and_QingyanGuo_Etal_Analysis/EvoPromptDemo.ipynb#X30sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m     )  \n",
      "File \u001b[1;32mc:\\Users\\danie\\.conda\\envs\\transformers\\lib\\site-packages\\openai\\api_resources\\chat_completion.py:25\u001b[0m, in \u001b[0;36mChatCompletion.create\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m     24\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 25\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mcreate(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     26\u001b[0m     \u001b[39mexcept\u001b[39;00m TryAgain \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     27\u001b[0m         \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m time\u001b[39m.\u001b[39mtime() \u001b[39m>\u001b[39m start \u001b[39m+\u001b[39m timeout:\n",
      "File \u001b[1;32mc:\\Users\\danie\\.conda\\envs\\transformers\\lib\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py:155\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[1;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[0;32m    130\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate\u001b[39m(\n\u001b[0;32m    131\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    138\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams,\n\u001b[0;32m    139\u001b[0m ):\n\u001b[0;32m    140\u001b[0m     (\n\u001b[0;32m    141\u001b[0m         deployment_id,\n\u001b[0;32m    142\u001b[0m         engine,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    152\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams\n\u001b[0;32m    153\u001b[0m     )\n\u001b[1;32m--> 155\u001b[0m     response, _, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39;49mrequest(\n\u001b[0;32m    156\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    157\u001b[0m         url,\n\u001b[0;32m    158\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[0;32m    159\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[0;32m    160\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[0;32m    161\u001b[0m         request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[0;32m    162\u001b[0m         request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[0;32m    163\u001b[0m     )\n\u001b[0;32m    165\u001b[0m     \u001b[39mif\u001b[39;00m stream:\n\u001b[0;32m    166\u001b[0m         \u001b[39m# must be an iterator\u001b[39;00m\n\u001b[0;32m    167\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[1;32mc:\\Users\\danie\\.conda\\envs\\transformers\\lib\\site-packages\\openai\\api_requestor.py:289\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[1;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[0;32m    278\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[0;32m    279\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    280\u001b[0m     method,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    287\u001b[0m     request_timeout: Optional[Union[\u001b[39mfloat\u001b[39m, Tuple[\u001b[39mfloat\u001b[39m, \u001b[39mfloat\u001b[39m]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    288\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[39mbool\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[1;32m--> 289\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrequest_raw(\n\u001b[0;32m    290\u001b[0m         method\u001b[39m.\u001b[39;49mlower(),\n\u001b[0;32m    291\u001b[0m         url,\n\u001b[0;32m    292\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[0;32m    293\u001b[0m         supplied_headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[0;32m    294\u001b[0m         files\u001b[39m=\u001b[39;49mfiles,\n\u001b[0;32m    295\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[0;32m    296\u001b[0m         request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[0;32m    297\u001b[0m         request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[0;32m    298\u001b[0m     )\n\u001b[0;32m    299\u001b[0m     resp, got_stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_interpret_response(result, stream)\n\u001b[0;32m    300\u001b[0m     \u001b[39mreturn\u001b[39;00m resp, got_stream, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key\n",
      "File \u001b[1;32mc:\\Users\\danie\\.conda\\envs\\transformers\\lib\\site-packages\\openai\\api_requestor.py:606\u001b[0m, in \u001b[0;36mAPIRequestor.request_raw\u001b[1;34m(self, method, url, params, supplied_headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[0;32m    604\u001b[0m     _thread_context\u001b[39m.\u001b[39msession_create_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m    605\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 606\u001b[0m     result \u001b[39m=\u001b[39m _thread_context\u001b[39m.\u001b[39;49msession\u001b[39m.\u001b[39;49mrequest(\n\u001b[0;32m    607\u001b[0m         method,\n\u001b[0;32m    608\u001b[0m         abs_url,\n\u001b[0;32m    609\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[0;32m    610\u001b[0m         data\u001b[39m=\u001b[39;49mdata,\n\u001b[0;32m    611\u001b[0m         files\u001b[39m=\u001b[39;49mfiles,\n\u001b[0;32m    612\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[0;32m    613\u001b[0m         timeout\u001b[39m=\u001b[39;49mrequest_timeout \u001b[39mif\u001b[39;49;00m request_timeout \u001b[39melse\u001b[39;49;00m TIMEOUT_SECS,\n\u001b[0;32m    614\u001b[0m         proxies\u001b[39m=\u001b[39;49m_thread_context\u001b[39m.\u001b[39;49msession\u001b[39m.\u001b[39;49mproxies,\n\u001b[0;32m    615\u001b[0m     )\n\u001b[0;32m    616\u001b[0m \u001b[39mexcept\u001b[39;00m requests\u001b[39m.\u001b[39mexceptions\u001b[39m.\u001b[39mTimeout \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    617\u001b[0m     \u001b[39mraise\u001b[39;00m error\u001b[39m.\u001b[39mTimeout(\u001b[39m\"\u001b[39m\u001b[39mRequest timed out: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(e)) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\danie\\.conda\\envs\\transformers\\lib\\site-packages\\requests\\sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    584\u001b[0m send_kwargs \u001b[39m=\u001b[39m {\n\u001b[0;32m    585\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m\"\u001b[39m: timeout,\n\u001b[0;32m    586\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mallow_redirects\u001b[39m\u001b[39m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    587\u001b[0m }\n\u001b[0;32m    588\u001b[0m send_kwargs\u001b[39m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 589\u001b[0m resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msend(prep, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39msend_kwargs)\n\u001b[0;32m    591\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32mc:\\Users\\danie\\.conda\\envs\\transformers\\lib\\site-packages\\requests\\sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    700\u001b[0m start \u001b[39m=\u001b[39m preferred_clock()\n\u001b[0;32m    702\u001b[0m \u001b[39m# Send the request\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m r \u001b[39m=\u001b[39m adapter\u001b[39m.\u001b[39msend(request, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    705\u001b[0m \u001b[39m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[0;32m    706\u001b[0m elapsed \u001b[39m=\u001b[39m preferred_clock() \u001b[39m-\u001b[39m start\n",
      "File \u001b[1;32mc:\\Users\\danie\\.conda\\envs\\transformers\\lib\\site-packages\\requests\\adapters.py:486\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    483\u001b[0m     timeout \u001b[39m=\u001b[39m TimeoutSauce(connect\u001b[39m=\u001b[39mtimeout, read\u001b[39m=\u001b[39mtimeout)\n\u001b[0;32m    485\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 486\u001b[0m     resp \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49murlopen(\n\u001b[0;32m    487\u001b[0m         method\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mmethod,\n\u001b[0;32m    488\u001b[0m         url\u001b[39m=\u001b[39;49murl,\n\u001b[0;32m    489\u001b[0m         body\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mbody,\n\u001b[0;32m    490\u001b[0m         headers\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mheaders,\n\u001b[0;32m    491\u001b[0m         redirect\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    492\u001b[0m         assert_same_host\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    493\u001b[0m         preload_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    494\u001b[0m         decode_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    495\u001b[0m         retries\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_retries,\n\u001b[0;32m    496\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[0;32m    497\u001b[0m         chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[0;32m    498\u001b[0m     )\n\u001b[0;32m    500\u001b[0m \u001b[39mexcept\u001b[39;00m (ProtocolError, \u001b[39mOSError\u001b[39;00m) \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m    501\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m(err, request\u001b[39m=\u001b[39mrequest)\n",
      "File \u001b[1;32mc:\\Users\\danie\\.conda\\envs\\transformers\\lib\\site-packages\\urllib3\\connectionpool.py:791\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    788\u001b[0m response_conn \u001b[39m=\u001b[39m conn \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m release_conn \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    790\u001b[0m \u001b[39m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[1;32m--> 791\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_request(\n\u001b[0;32m    792\u001b[0m     conn,\n\u001b[0;32m    793\u001b[0m     method,\n\u001b[0;32m    794\u001b[0m     url,\n\u001b[0;32m    795\u001b[0m     timeout\u001b[39m=\u001b[39mtimeout_obj,\n\u001b[0;32m    796\u001b[0m     body\u001b[39m=\u001b[39mbody,\n\u001b[0;32m    797\u001b[0m     headers\u001b[39m=\u001b[39mheaders,\n\u001b[0;32m    798\u001b[0m     chunked\u001b[39m=\u001b[39mchunked,\n\u001b[0;32m    799\u001b[0m     retries\u001b[39m=\u001b[39mretries,\n\u001b[0;32m    800\u001b[0m     response_conn\u001b[39m=\u001b[39mresponse_conn,\n\u001b[0;32m    801\u001b[0m     preload_content\u001b[39m=\u001b[39mpreload_content,\n\u001b[0;32m    802\u001b[0m     decode_content\u001b[39m=\u001b[39mdecode_content,\n\u001b[0;32m    803\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mresponse_kw,\n\u001b[0;32m    804\u001b[0m )\n\u001b[0;32m    806\u001b[0m \u001b[39m# Everything went great!\u001b[39;00m\n\u001b[0;32m    807\u001b[0m clean_exit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\danie\\.conda\\envs\\transformers\\lib\\site-packages\\urllib3\\connectionpool.py:537\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[0;32m    535\u001b[0m \u001b[39m# Receive the response from the server\u001b[39;00m\n\u001b[0;32m    536\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 537\u001b[0m     response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49mgetresponse()\n\u001b[0;32m    538\u001b[0m \u001b[39mexcept\u001b[39;00m (BaseSSLError, \u001b[39mOSError\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    539\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_raise_timeout(err\u001b[39m=\u001b[39me, url\u001b[39m=\u001b[39murl, timeout_value\u001b[39m=\u001b[39mread_timeout)\n",
      "File \u001b[1;32mc:\\Users\\danie\\.conda\\envs\\transformers\\lib\\site-packages\\urllib3\\connection.py:461\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    458\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mresponse\u001b[39;00m \u001b[39mimport\u001b[39;00m HTTPResponse\n\u001b[0;32m    460\u001b[0m \u001b[39m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[1;32m--> 461\u001b[0m httplib_response \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mgetresponse()\n\u001b[0;32m    463\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    464\u001b[0m     assert_header_parsing(httplib_response\u001b[39m.\u001b[39mmsg)\n",
      "File \u001b[1;32mc:\\Users\\danie\\.conda\\envs\\transformers\\lib\\http\\client.py:1375\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1373\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1374\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1375\u001b[0m         response\u001b[39m.\u001b[39;49mbegin()\n\u001b[0;32m   1376\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m:\n\u001b[0;32m   1377\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\Users\\danie\\.conda\\envs\\transformers\\lib\\http\\client.py:318\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    316\u001b[0m \u001b[39m# read until we get a non-100 response\u001b[39;00m\n\u001b[0;32m    317\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m--> 318\u001b[0m     version, status, reason \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_read_status()\n\u001b[0;32m    319\u001b[0m     \u001b[39mif\u001b[39;00m status \u001b[39m!=\u001b[39m CONTINUE:\n\u001b[0;32m    320\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\danie\\.conda\\envs\\transformers\\lib\\http\\client.py:279\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    278\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_read_status\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m--> 279\u001b[0m     line \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfp\u001b[39m.\u001b[39;49mreadline(_MAXLINE \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m), \u001b[39m\"\u001b[39m\u001b[39miso-8859-1\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    280\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(line) \u001b[39m>\u001b[39m _MAXLINE:\n\u001b[0;32m    281\u001b[0m         \u001b[39mraise\u001b[39;00m LineTooLong(\u001b[39m\"\u001b[39m\u001b[39mstatus line\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\danie\\.conda\\envs\\transformers\\lib\\socket.py:705\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    703\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m    704\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 705\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv_into(b)\n\u001b[0;32m    706\u001b[0m     \u001b[39mexcept\u001b[39;00m timeout:\n\u001b[0;32m    707\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout_occurred \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\danie\\.conda\\envs\\transformers\\lib\\ssl.py:1274\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1270\u001b[0m     \u001b[39mif\u001b[39;00m flags \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m   1271\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1272\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[0;32m   1273\u001b[0m           \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m)\n\u001b[1;32m-> 1274\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(nbytes, buffer)\n\u001b[0;32m   1275\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1276\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[1;32mc:\\Users\\danie\\.conda\\envs\\transformers\\lib\\ssl.py:1130\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1128\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1129\u001b[0m     \u001b[39mif\u001b[39;00m buffer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1130\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sslobj\u001b[39m.\u001b[39;49mread(\u001b[39mlen\u001b[39;49m, buffer)\n\u001b[0;32m   1131\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1132\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sslobj\u001b[39m.\u001b[39mread(\u001b[39mlen\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "evoprompt_ga(3, 4, \"Yes, the two sentences convey the same meaning.\\n\\nIn both sentences, the subject is a dog that is actively searching for a buried bone. In both sentences, the dog is described as being eager, excited, and motivated to find the bone. Additionally, both sentences indicate that the bone was buried by the dog and that it had been buried the previous day.\\n\\nAlthough the wording and phrasing differ slightly between the two sentences, the overall message and intent of both sentences are the same. The use of synonyms like \\\"dug up\\\" and \\\"unearthed,\\\" \\\"find\\\" and \\\"retrieve,\\\" and \\\"buried\\\" and \\\"stashed away\\\" adds some variation in phrasing, but the essential meaning remains consistent.\\n\\nTherefore, after analyzing the context and synonyms used, it can be concluded that the two sentences convey the same meaning.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are an AI assistant who accomplishes its task as best as possible.\n",
    "\n",
    "Do the following two sentences mean the same thing.\n",
    "\n",
    "Sentence 1: The dog eagerly dug up the ground to find the bone it had buried yesterday.\n",
    "\n",
    "Sentence 2: Excited to retrieve what it hid, the dog unearthed the bone it stashed away the previous day\n",
    "\n",
    "Explain how you came to your conclusion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is what we are going to try to a build a better prompt for:\n",
    "\n",
    "The following are two sentences:\n",
    "\n",
    "- Sentence 1: The dog eagerly dug up the ground to find the bone it had buried yesterday.\n",
    "- Sentence 2: Excited to retrieve what it hid, the dog unearthed the bone it stashed away the previous day.\n",
    "\n",
    "We need to construct a prompt which accomplishes two things. First, do the sentences convey the same meaning, and second explain why or why not. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are an AI assistant. You will be given a task. Complete the task and explain in detail how you came to your conclusion.\n",
    "\n",
    "Your task is to determine if the following two sentences convey the same meaning. First, answer either with yes or no, then explain your reasoning. \n",
    "Sentence 1: The dog eagerly dug up the ground to find the bone it had buried yesterday.\n",
    "Sentence 2: Excited to retrieve what it hid, the dog unearthed the bone it stashed away the previous day."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EvoPrompt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
